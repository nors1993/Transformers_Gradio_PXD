import gradio as gr
import os
import time
import gradio as gr
from typing import List, Optional, Tuple, Dict
#from FT.FT_infer_lora import infer_pt
from swift.llm import (PtEngine, RequestConfig, AdapterRequest, get_template, BaseArguments, InferRequest,
                           safe_snapshot_download)


os.environ['CUDA_VISIBLE_DEVICES'] = '0'

History = List[Tuple[str, str]] # æ¯æ¡æ¶ˆæ¯åº”ä¸ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå…ƒç´ ï¼ˆqueryï¼Œresponseï¼‰çš„å…ƒç»„

def infer_pt(query: Optional[str], chat_history: History):
    
    adapter_path = r"output\v20-20241230-225736\checkpoint-10"
    args = BaseArguments.from_pretrained(adapter_path)
    engine = PtEngine(args.model, adapters=[adapter_path])
    template = get_template(args.template, engine.tokenizer, args.system)
    request_config = RequestConfig(max_tokens=512, temperature=0)
    infer_request = InferRequest(messages=[{'role': 'user', 'content': query}])
    # use lora
    resp_list = engine.infer([infer_request], request_config, template=template)
    response_lora = resp_list[0].choices[0].message.content
    #print(f'lora-response: {response_lora}')
    chat_history.append((query, response_lora))    
    # for resp in chat_history[-1][1]:  # æ‰“å°æœ€åä¸€è¡ŒèŠå¤©è®°å½•çš„responseï¼Œé€å­—æ˜¾ç¤º
    #     print(resp, end='', flush=True)
    #     time.sleep(0.05)
    
    yield "", chat_history
 
    

# å®šä¹‰é¡µé¢æ€»ä½“å¸ƒå±€
css = """.my-group {max-width: 600px !important; max-height: 600 !important;}
                     .my-column {display: flex !important; justify-content: center !important; align-items: center !important};"""
with gr.Blocks(css=css) as demo:
    #gr.Markdown(value=f"<center><font size=8>PXDçš„åŠ©æ‰‹ï¼ˆSFT on Qwen2.5-0.5B-Instruct)</center>")\
    gr.HTML(
        """
    <h1 style='text-align: center'
    >PXDçš„åŒ»ç–—åŠ©æ‰‹
    </h1>
    """
    )
    gr.HTML(
    """
    <h3 style="text-align: center">
    <a href="https://github.com/nors1993/Transformers_Gradio_PXD" target="_blank">Made by PXD</a>
    </h3>
    """
    )
    with gr.Row():
        chatbot = gr.Chatbot(label="æœºå™¨äººåŒ»ç”Ÿ")  # åˆ›å»ºä¸€ä¸ªèŠå¤©æœºå™¨äººï¼ŒåŒ…å«queryå’Œresponseï¼ˆå³chat_historyï¼‰
    with gr.Row():
        user_input = gr.Textbox(label="è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š", placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")
    with gr.Row():
        with gr.Column():
            submit_button = gr.Button("ğŸ¥³æäº¤")
        with gr.Column():
            clear_button = gr.Button("ğŸ§¹æ¸…ç©ºå†å²è®°å½•")

    # inputs=[user_input, chatbot]è¡¨ç¤ºinfer_ptå‡½æ•°çš„è¾“å…¥å‚æ•°ä¸ºuser_inputå’Œchatbot
    # outputs=[user_input, chatbot]è¡¨ç¤ºinfer_ptå‡½æ•°çš„è¾“å‡ºå‚æ•°ä¸ºuser_inputå’Œchatbot
    submit_button.click(fn=infer_pt, inputs=[user_input, chatbot], outputs=[user_input, chatbot])  # ç‚¹å‡»æŒ‰é’®æäº¤
    user_input.submit(fn=infer_pt, inputs=[user_input, chatbot], outputs=[user_input, chatbot])  # ç”¨æˆ·æŒ‰å›è½¦é”®ä¹Ÿå¯ä»¥æäº¤
    clear_button.click(lambda: None, None, chatbot)

demo.launch()